{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwnaCYVuZDunymhm3y+CC+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csce585-mlsystems/CSCE585ProjectROI/blob/michelleBranch/Intro_Parsers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnKlZSiZI4Wb"
      },
      "outputs": [],
      "source": [
        "INTEGER, PLUS, EOF = 'INTEGER', 'PLUS', 'EOF'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Token(object):\n",
        "  def __init__(self, type, value):\n",
        "    self.type = type\n",
        "    self.value = value #setting token values\n",
        "\n",
        "def __init__(self):\n",
        "  Token(INTEGER, 3)\n",
        "  Token(PLUS, '+')\n",
        "\n",
        "  return 'Token({type}, {value})'.format(\n",
        "      type=self.type,\n",
        "      value=repr(self.value)\n",
        "  )\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.__str__()"
      ],
      "metadata": {
        "id": "6ZFc9XS5KZGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Interperter(object):\n",
        "  def __init__(self, text):\n",
        "    self.text = text #string input\n",
        "    self.pos = 0 #index of self.text\n",
        "    self.current_token = None #current token instance"
      ],
      "metadata": {
        "id": "ZijqnGJJMgWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import raiseExceptions\n",
        "def error(self):\n",
        "  raise Exceptions('Error parsing input')"
      ],
      "metadata": {
        "id": "Ldp4sZAwNp6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_token(self): #break down sentences into tokenizers\n",
        "  text = self.text\n",
        "  if self.pos > len(text) - 1:\n",
        "    return Token(EOF, None) #end of token stop?\n",
        "  current_char = text[self.pos] #current character\n",
        "\n",
        "  if current_char.isdigit():\n",
        "    token = Token(INTEGER, int(current_char))\n",
        "    self.pos += 1\n",
        "    return token\n",
        "  self.error()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b4R1gE57OaQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eat(self, token_type): #moving forward to the next token which will become current\n",
        "  if self.current_token.type == token_type:\n",
        "    self.current_token = self.get_next_token()\n",
        "  else:\n",
        "    self.error()"
      ],
      "metadata": {
        "id": "zoUxX1heQN8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expr(self):\n",
        "  self.current_token = self.get_next_token() #set current token to the first token\n",
        "  left = self.current_token #current token should be single digit integer\n",
        "  self.eat(INTEGER)\n",
        "  op = self.current_token #current token is +\n",
        "  self.eat(PLUS)\n",
        "  right = self.current_token\n",
        "  self.eat(INTEGER) #current token is single digit integer\n",
        "  result = left.value + right.value\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "iSFuLtJ3Q5nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  while True:\n",
        "    try:\n",
        "      text = raw_input('calc>')\n",
        "    except EOFError:\n",
        "        break\n",
        "    if not text:\n",
        "      continue\n",
        "    interpreter = Interperter(text)\n",
        "    result = interperter.expr()\n",
        "    print(result)\n"
      ],
      "metadata": {
        "id": "K8bc3T0NSF-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A complier understands input as tokens which is an object that has a type and value.\n",
        "\n",
        "Lexical Analysis: The process of breaking input strings into tokens it the get_next_token method of the interpeter\n",
        "\n",
        "input is stored in the variable text and pos is an index into that string\n",
        "\n",
        "POS stands for parts of speech\n",
        "\n",
        "where pos is set to 0 and points to the string chatacter 3 to check if the character is a whole number\n",
        "\n",
        "If pos is a whole number it moves forward (increment) and return an integer token and value is set to the string value '3'\n",
        "\n",
        "step 1: lexical analysis\n"
      ],
      "metadata": {
        "id": "GwgpmKyeTDAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpeter expects to find the following structure\n",
        "INTEGER -> PLUS -> INTEGER\n",
        "\n",
        "expr is the method that finds and interpets the arithimic expression in the calcuator and returns an integer value\n",
        "\n",
        "eat is an expr helper method that verifies the token is passed thru the eat method and advancing the imaginary pointer in the stream of tokens"
      ],
      "metadata": {
        "id": "3jTarP5HWttv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lexeme is a sequence of characters that form a token\n",
        "\n",
        "Expr method: interperts the input as a phrase add , sub, mutli etc\n",
        "recognize(parse) and interpet\n",
        "\n",
        "Parsing: the process of recognizing a phrase within a stream of tokens"
      ],
      "metadata": {
        "id": "d5CKkxXZZdYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def term(self):\n",
        "    self.eat(INTEGER)\n",
        "\n",
        "def expr(self):\n",
        "    # set current token to the first token taken from the input\n",
        "    self.current_token = self.get_next_token()\n",
        "\n",
        "    self.term()\n",
        "    while self.current_token.type in (PLUS, MINUS):\n",
        "        token = self.current_token\n",
        "        if token.type == PLUS:\n",
        "            self.eat(PLUS)\n",
        "            self.term()\n",
        "        elif token.type == MINUS:\n",
        "            self.eat(MINUS)\n",
        "            self.term()"
      ],
      "metadata": {
        "id": "nRmPtKz_Z-z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we add interpeter code"
      ],
      "metadata": {
        "id": "mWbl1OBubIfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def term(self):\n",
        "    \"\"\"Return an INTEGER token value\"\"\"\n",
        "    token = self.current_token\n",
        "    self.eat(INTEGER)\n",
        "    return token.value\n",
        "\n",
        "def expr(self):\n",
        "    \"\"\"Parser / Interpreter \"\"\"\n",
        "    # set current token to the first token taken from the input\n",
        "    self.current_token = self.get_next_token()\n",
        "\n",
        "    result = self.term()\n",
        "    while self.current_token.type in (PLUS, MINUS):\n",
        "        token = self.current_token\n",
        "        if token.type == PLUS:\n",
        "            self.eat(PLUS)\n",
        "            result = result + self.term()\n",
        "        elif token.type == MINUS:\n",
        "            self.eat(MINUS)\n",
        "            result = result - self.term()"
      ],
      "metadata": {
        "id": "gjBygm7iZajy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Token types\n",
        "#\n",
        "# EOF (end-of-file) token is used to indicate that\n",
        "# there is no more input left for lexical analysis\n",
        "INTEGER, PLUS, MINUS, EOF = 'INTEGER', 'PLUS', 'MINUS', 'EOF'\n",
        "\n",
        "\n",
        "class Token(object):\n",
        "    def __init__(self, type, value):\n",
        "        # token type: INTEGER, PLUS, MINUS, or EOF\n",
        "        self.type = type\n",
        "        # token value: non-negative integer value, '+', '-', or None\n",
        "        self.value = value\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"String representation of the class instance.\n",
        "\n",
        "        Examples:\n",
        "            Token(INTEGER, 3)\n",
        "            Token(PLUS, '+')\n",
        "        \"\"\"\n",
        "        return 'Token({type}, {value})'.format(\n",
        "            type=self.type,\n",
        "            value=repr(self.value)\n",
        "        )\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "\n",
        "\n",
        "class Interpreter(object):\n",
        "    def __init__(self, text):\n",
        "        # client string input, e.g. \"3 + 5\", \"12 - 5 + 3\", etc\n",
        "        self.text = text\n",
        "        # self.pos is an index into self.text\n",
        "        self.pos = 0\n",
        "        # current token instance\n",
        "        self.current_token = None\n",
        "        self.current_char = self.text[self.pos]\n",
        "\n",
        "    ##########################################################\n",
        "    # Lexer code                                             #\n",
        "    ##########################################################\n",
        "    def error(self):\n",
        "        raise Exception('Invalid syntax')\n",
        "\n",
        "    def advance(self):\n",
        "        \"\"\"Advance the `pos` pointer and set the `current_char` variable.\"\"\"\n",
        "        self.pos += 1\n",
        "        if self.pos > len(self.text) - 1:\n",
        "            self.current_char = None  # Indicates end of input\n",
        "        else:\n",
        "            self.current_char = self.text[self.pos]\n",
        "\n",
        "    def skip_whitespace(self):\n",
        "        while self.current_char is not None and self.current_char.isspace():\n",
        "            self.advance()\n",
        "\n",
        "    def integer(self):\n",
        "        \"\"\"Return a (multidigit) integer consumed from the input.\"\"\"\n",
        "        result = ''\n",
        "        while self.current_char is not None and self.current_char.isdigit():\n",
        "            result += self.current_char\n",
        "            self.advance()\n",
        "        return int(result)\n",
        "\n",
        "    def get_next_token(self):\n",
        "        \"\"\"Lexical analyzer (also known as scanner or tokenizer)\n",
        "\n",
        "        This method is responsible for breaking a sentence\n",
        "        apart into tokens. One token at a time.\n",
        "        \"\"\"\n",
        "        while self.current_char is not None:\n",
        "\n",
        "            if self.current_char.isspace():\n",
        "                self.skip_whitespace()\n",
        "                continue\n",
        "\n",
        "            if self.current_char.isdigit():\n",
        "                return Token(INTEGER, self.integer())\n",
        "\n",
        "            if self.current_char == '+':\n",
        "                self.advance()\n",
        "                return Token(PLUS, '+')\n",
        "\n",
        "            if self.current_char == '-':\n",
        "                self.advance()\n",
        "                return Token(MINUS, '-')\n",
        "\n",
        "            self.error()\n",
        "\n",
        "        return Token(EOF, None)\n",
        "\n",
        "    ##########################################################\n",
        "    # Parser / Interpreter code                              #\n",
        "    ##########################################################\n",
        "    def eat(self, token_type):\n",
        "        # compare the current token type with the passed token\n",
        "        # type and if they match then \"eat\" the current token\n",
        "        # and assign the next token to the self.current_token,\n",
        "        # otherwise raise an exception.\n",
        "        if self.current_token.type == token_type:\n",
        "            self.current_token = self.get_next_token()\n",
        "        else:\n",
        "            self.error()\n",
        "\n",
        "    def term(self):\n",
        "        \"\"\"Return an INTEGER token value.\"\"\"\n",
        "        token = self.current_token\n",
        "        self.eat(INTEGER)\n",
        "        return token.value\n",
        "\n",
        "    def expr(self):\n",
        "        \"\"\"Arithmetic expression parser / interpreter.\"\"\"\n",
        "        # set current token to the first token taken from the input\n",
        "        self.current_token = self.get_next_token()\n",
        "\n",
        "        result = self.term()\n",
        "        while self.current_token.type in (PLUS, MINUS):\n",
        "            token = self.current_token\n",
        "            if token.type == PLUS:\n",
        "                self.eat(PLUS)\n",
        "                result = result + self.term()\n",
        "            elif token.type == MINUS:\n",
        "                self.eat(MINUS)\n",
        "                result = result - self.term()\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "def main():\n",
        "    while True:\n",
        "        try:\n",
        "            # To run under Python3 replace 'raw_input' call\n",
        "            # with 'input'\n",
        "            text = input('calc> ')\n",
        "        except EOFError:\n",
        "            break\n",
        "        if not text:\n",
        "            continue\n",
        "        interpreter = Interpreter(text)\n",
        "        result = interpreter.expr()\n",
        "        print(result)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "kR15wbpCWp2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "SHtfBD79SzYH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}