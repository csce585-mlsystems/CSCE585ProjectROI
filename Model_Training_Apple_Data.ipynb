{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csce585-mlsystems/CSCE585ProjectROI/blob/michelleBranch/Model_Training_Apple_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1EeQB0JALeg"
      },
      "source": [
        "\n",
        "\n",
        "> Running experiments in ModelDevelopment Directory\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2adebab3"
      },
      "source": [
        "Cloned the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a4c23e5",
        "outputId": "cfc407bc-7fac-41a0-bdb3-235e37dc0550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CSCE585ProjectROI'...\n",
            "remote: Enumerating objects: 563, done.\u001b[K\n",
            "remote: Counting objects: 100% (259/259), done.\u001b[K\n",
            "remote: Compressing objects: 100% (199/199), done.\u001b[K\n",
            "remote: Total 563 (delta 107), reused 165 (delta 57), pack-reused 304 (from 1)\u001b[K\n",
            "Receiving objects: 100% (563/563), 1.50 MiB | 11.27 MiB/s, done.\n",
            "Resolving deltas: 100% (248/248), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/csce585-mlsystems/CSCE585ProjectROI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f49a1ff"
      },
      "source": [
        "After cloning, you might need to navigate into the repository's directory. Then, install any necessary Python packages. Often, these are listed in a `requirements.txt` file. You may need to check the repository's documentation for the exact file name or commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da7e07c9"
      },
      "outputs": [],
      "source": [
        "# Repo directories\n",
        "import os\n",
        "os.chdir('CSCE585ProjectROI')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlEl9RhkCY4b"
      },
      "source": [
        "Here I'm uploading my dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZJKkZ7hCRy1",
        "outputId": "55421c4a-1832-464a-c010-7849e02b4c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reactpy in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: reactpy-router in /usr/local/lib/python3.12/dist-packages (2.0.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: llama-cpp-python in /usr/local/lib/python3.12/dist-packages (0.3.16)\n",
            "Requirement already satisfied: TensorFlow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: anyio>=3 in /usr/local/lib/python3.12/dist-packages (from reactpy) (4.11.0)\n",
            "Requirement already satisfied: asgiref>=3 in /usr/local/lib/python3.12/dist-packages (from reactpy) (3.11.0)\n",
            "Requirement already satisfied: colorlog>=6 in /usr/local/lib/python3.12/dist-packages (from reactpy) (6.10.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0 in /usr/local/lib/python3.12/dist-packages (from reactpy) (1.3.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.14.5 in /usr/local/lib/python3.12/dist-packages (from reactpy) (2.21.2)\n",
            "Requirement already satisfied: jsonpatch>=1.32 in /usr/local/lib/python3.12/dist-packages (from reactpy) (1.33)\n",
            "Requirement already satisfied: lxml>=4 in /usr/local/lib/python3.12/dist-packages (from reactpy) (6.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from reactpy) (1.1.0)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.12/dist-packages (from reactpy) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.10 in /usr/local/lib/python3.12/dist-packages (from reactpy) (4.15.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python) (2.0.2)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from TensorFlow) (0.5.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio>=3->reactpy) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=3->reactpy) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->TensorFlow) (0.45.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch>=1.32->reactpy) (3.0.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->TensorFlow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->TensorFlow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->TensorFlow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2->reactpy) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2->reactpy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2->reactpy) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->TensorFlow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->TensorFlow) (0.7.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->TensorFlow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->TensorFlow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->TensorFlow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install reactpy reactpy-router flask llama-cpp-python TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2RPTVEID6AX",
        "outputId": "f1633fc9-5b37-454c-de47-4d5bad3159ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46FBlBCYEGEq"
      },
      "source": [
        "Verified that the notebook is running from python 3.12.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP-pNe7RG4ra"
      },
      "source": [
        "Uploading Specific libaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5sfsVGjHGxvC"
      },
      "outputs": [],
      "source": [
        "# Body of neccessary imports\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np #<-- May be optional not sure as of 10/13/25.\n",
        "# import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvHV93GvI2jY"
      },
      "source": [
        "Uploaded the model from local computer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "_UbBzt51UO3s",
        "outputId": "30717fd0-da5d-40ff-8d7c-8d9a05554c03"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7dc23fdb-e5f3-46c2-92c2-3b4b55f44034\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7dc23fdb-e5f3-46c2-92c2-3b4b55f44034\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving set1FinalCopy.py to set1FinalCopy.py\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "model = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZN3owfPkUn6x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "53466b2c-bf3c-44e9-c1a8-dc0b34058ae0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a9925519-f240-46c3-bba9-62d6ea1fc3a6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a9925519-f240-46c3-bba9-62d6ea1fc3a6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving apple_Metrics.csv to apple_Metrics.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "apple = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPVN1jIoU2dK"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "google = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MsNN8a0JpE0"
      },
      "source": [
        "Step 1: Split data into training group, validation and test sets\n",
        "\n",
        "X : Features\n",
        "\n",
        "y : Target variable of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2R2lyTvLI6-J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iHhpt9udWZM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6410974-791d-4053-afe7-d73890cd8445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple DataFrame processed successfully from file system.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Path to the apple_Metrics.csv file in the cloned repository\n",
        "file_path = 'apple_Metrics.csv'\n",
        "\n",
        "# Read the CSV directly from the file system\n",
        "df_raw = pd.read_csv(file_path)\n",
        "\n",
        "# Set the 'Metric' column as the index, then transpose the DataFrame\n",
        "apple = df_raw.set_index('Metric').T\n",
        "\n",
        "# The index is now dates; optionally, reset it to make 'Date' a column\n",
        "apple.index.name = 'Date'\n",
        "apple = apple.reset_index()\n",
        "\n",
        "# Convert 'Date' column to datetime objects and sort\n",
        "apple['Date'] = pd.to_datetime(apple['Date'])\n",
        "apple = apple.sort_values(by='Date')\n",
        "\n",
        "# Strip any potential whitespace from column names for easier access\n",
        "apple.columns = apple.columns.str.strip()\n",
        "\n",
        "print(\"Apple DataFrame processed successfully from file system.\")\n",
        "# You may want to inspect apple.head() and apple.columns here to confirm the structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCRKeGl7XVxm"
      },
      "outputs": [],
      "source": [
        "for fn in google.keys():\n",
        "  google = pd.read_csv(io.StringIO(google[fn].decode('utf-8')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE8RAAAVaXiK"
      },
      "source": [
        "Here I'm defining X and y values for the Apple dataset where my metrics will be X values and dates will be y value\n",
        "\n",
        "I extracted my feature columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f11f8b6",
        "outputId": "254b8ac8-da5a-48cc-8049-a9696b4d220a"
      },
      "source": [
        "feature_columns = [\n",
        "    \"Operating Cash Flow\",\n",
        "    \"Capital Expenditure\",\n",
        "    \"Free Cash Flow\",\n",
        "    \"Total Debt\",\n",
        "    \"Common Stockholder Equity\",\n",
        "    \"Total Liabilities Net Minority Interest\",\n",
        "    \"Total Assets\",\n",
        "    \"Shares Outstanding\",\n",
        "    \"Net Income Common Stockholders\",\n",
        "    \"Diluted Average Shares\",\n",
        "    \"Diluted EPS\"\n",
        "]\n",
        "\n",
        "# Extract X (features) and y (target 'Price') from the apple DataFrame\n",
        "X_data = apple[feature_columns]\n",
        "y_data = apple['Price']\n",
        "\n",
        "print(\"Features (X_data) head:\\n\", X_data.head())\n",
        "print(\"\\nTarget (y_data) head:\\n\", y_data.head())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X_data) head:\n",
            " Metric  Operating Cash Flow  Capital Expenditure  Free Cash Flow   Total Debt  \\\n",
            "4                28858000.0           -2151000.0      26707000.0  101304000.0   \n",
            "3                26811000.0           -2908000.0      23903000.0  106629000.0   \n",
            "2                29935000.0           -2940000.0      26995000.0   96799000.0   \n",
            "1                23952000.0           -3071000.0      20881000.0   98186000.0   \n",
            "0                27867000.0            3462000.0      24405000.0  101698000.0   \n",
            "\n",
            "Metric  Common Stockholder Equity  Total Liabilities Net Minority Interest  \\\n",
            "4                      66708000.0                              264904000.0   \n",
            "3                      56950000.0                              308030000.0   \n",
            "2                      66758000.0                              277327000.0   \n",
            "1                      66796000.0                              264437000.0   \n",
            "0                      65830000.0                              265665000.0   \n",
            "\n",
            "Metric  Total Assets  Shares Outstanding  Net Income Common Stockholders  \\\n",
            "4        331612000.0          15222259.0                      21448000.0   \n",
            "3        364980000.0          15116786.0                      14736000.0   \n",
            "2        344085000.0          15037874.0                      36330000.0   \n",
            "1        331233000.0          14939315.0                      24780000.0   \n",
            "0        331495000.0          14856722.0                      23434000.0   \n",
            "\n",
            "Metric  Diluted Average Shares  Diluted EPS  \n",
            "4                   15348175.0         1.40  \n",
            "3                   15242853.0         0.97  \n",
            "2                   15150865.0         2.40  \n",
            "1                   15056133.0         1.65  \n",
            "0                   14948179.0         1.57  \n",
            "\n",
            "Target (y_data) head:\n",
            " 4    220.80\n",
            "3    224.86\n",
            "2    235.17\n",
            "1    211.98\n",
            "0    207.33\n",
            "Name: Price, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96ec93f1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Perform the train-test split on the actual data\n",
        "X_train_data, X_test_data, y_train_data, y_test_data = train_test_split(X_data, y_data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Display the shapes to confirm\n",
        "print(\"Shape of X_train_data:\", X_train_data.shape)\n",
        "print(\"Shape of y_train_data:\", y_train_data.shape)\n",
        "print(\"Shape of X_test_data:\", X_test_data.shape)\n",
        "print(\"Shape of y_test_data:\", y_test_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I have to define my validation data which is 50% of combined dataset"
      ],
      "metadata": {
        "id": "_0HcTAwSBkTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_main = X_train_data, X_test_data\n",
        "y_main = y_train_data, y_test_data\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_main, y_main, test_size=0.25, random_state=42)\n",
        "\n",
        "print(X_train_data, X_val, y_train, y_val)"
      ],
      "metadata": {
        "id": "5gRN1aspB4C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation set is 50% of combined dataset\n",
        "x_val, x_test, y_val, y_test = train_test_split(X_main,\n",
        "                                                y_main,\n",
        "                                                test_size=0.5,\n",
        "                                                random_state=42)\n",
        "print(x_val, x_test, y_val, y_test)"
      ],
      "metadata": {
        "id": "SeE-4FcrFiN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apple Data\n",
        "\n",
        "Training : X_train, y_train\n",
        "\n",
        "Validation : X_main, y_main\n",
        "\n",
        "Test : X_test, y_test"
      ],
      "metadata": {
        "id": "99006Oj8Cxnw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRd45zUmJ7YY"
      },
      "source": [
        "Step 2: Use data leakage prevention techniques such as walk forward cross validation\n",
        "\n",
        "Update I'm going to go with standard walk forward validation since the current dataset we have is small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYXutZWtKOUb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def perform_walk_forward_validation(apple, training_window_size, testing_window_size, step_size):\n",
        "    errors = []\n",
        "    predictions = []\n",
        "\n",
        "    # Ensure data is a pandas Series or DataFrame with a time-based index\n",
        "    # For this example, assuming 'data' is a Series where the index represents time\n",
        "\n",
        "    for i in range(training_window_size, len(data) - testing_window_size + 1, step_size):\n",
        "        # Define training and testing windows\n",
        "        train_data = data.iloc[i - training_window_size : i]\n",
        "        test_data = data.iloc[i : i + testing_window_size]\n",
        "\n",
        "        # In a real scenario, you'd extract features (X) and target (y)\n",
        "        # For this simple example, we'll just predict the next value based on previous values\n",
        "        X_train = pd.DataFrame({'lag1': train_data.shift(1).dropna()})\n",
        "        y_train = train_data.iloc[1:] # Target is the actual value at the next step\n",
        "\n",
        "        X_test = pd.DataFrame({'lag1': test_data.shift(1).dropna()})\n",
        "        y_test = test_data.iloc[1:]\n",
        "\n",
        "        # Handle cases where X_train or X_test might be empty or too small\n",
        "        if X_train.empty or X_test.empty:\n",
        "            continue\n",
        "\n",
        "        # Train the model\n",
        "        model = LinearRegression()\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Evaluate and store results\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        errors.append(mse)\n",
        "        predictions.extend(y_pred)\n",
        "\n",
        "    return errors, predictions\n",
        "\n",
        "\n",
        "training_window = 30 # Use 30 days for training\n",
        "testing_window = 7   # Predict for the next 7 days\n",
        "step = 7             # Move forward by 7 days in each iteration\n",
        "\n",
        "errors, predictions = perform_walk_forward_validation(data, training_window, testing_window, step)\n",
        "\n",
        "print(f\"Mean Squared Errors for each fold: {errors}\")\n",
        "print(f\"Average MSE: {sum(errors) / len(errors) if errors else 'N/A'}\")"
      ],
      "metadata": {
        "id": "byJBzKsvJogi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujbGNhaOKOpA"
      },
      "source": [
        "Step 3: Hypertune the parameters using the validation data set\n",
        "\n",
        "I'm going to use the random search technique since we are working with financial stock data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline with scaling and the linear model\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('linear_model', Ridge()) # Or Lasso, etc.\n",
        "])\n"
      ],
      "metadata": {
        "id": "4Fp8yDo5mMZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eS0CAkGWKepS"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import uniform, loguniform\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Define the search space\n",
        "param_distributions = {\n",
        "    'linear_model__alpha': loguniform(1e-4, 1e3), # Example for Ridge\n",
        "    # Add other parameters for other models as needed\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Initialize the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(\n",
        "    pipeline,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=100, # Number of random combinations to try\n",
        "    cv=3, # Number of cross-validation folds, changed from 5 to 3\n",
        "    scoring='neg_mean_squared_error', # Or other scoring metrics\n",
        "    random_state=42,\n",
        "    n_jobs=-1 # Use all available CPU cores\n",
        ")\n",
        "\n",
        "# Fit the search object to your training data using the correct variables\n",
        "random_search.fit(X_train_data, y_train_data)\n"
      ],
      "metadata": {
        "id": "ZGLdS75VcHtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc2dwlQEKfAd"
      },
      "source": [
        "Since we are measuring numerical values it would be best to use regression based evaluations such as MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlZG-vwenUY3"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "from datetime import timedelta"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch yfinance data then pass it thru the fucntion fetch market data so it can make future predicitions"
      ],
      "metadata": {
        "id": "26Nmyfnc-y08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yfinance"
      ],
      "metadata": {
        "id": "tYM2EYJ__Fyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "# Define the ticker symbol\n",
        "ticker_symbol = \"AAPL\"\n",
        "\n",
        "# Create a Ticker object\n",
        "ticker = yf.Ticker(ticker_symbol)\n",
        "\n",
        "# Fetch historical market data\n",
        "historical_data = ticker.history(period=\"1y\")  # data for the last year\n",
        "print(\"Historical Data:\")\n",
        "print(historical_data)\n",
        "\n",
        "# Fetch basic financials\n",
        "financials = ticker.financials.dropna()\n",
        "print(\"\\nFinancials:\")\n",
        "print(financials)\n",
        "\n",
        "# Fetch stock actions like dividends and splits\n",
        "actions = ticker.actions.dropna()\n",
        "print(\"\\nStock Actions:\")\n",
        "print(actions)"
      ],
      "metadata": {
        "id": "PjiMzQk3_L_N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8a7RqImP/pjU8uR/qt+8e",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}